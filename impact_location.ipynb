{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import kurtosis, skew\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import find_peaks, welch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracies\n",
    "\n",
    "The accuracies of the trained models are as follows:\n",
    "\n",
    "- **Neural Network**: 94%, test_accuracy: 93.7%\n",
    "- **XGBoost Classifier**: 92.6%\n",
    "- **Support Vector Machine (SVM)**: 86%\n",
    "- **Random Forest**: 96.03%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensorA  sensorB  sensorC  sensorD  sampleNo typeofimpact position     x  \\\n",
      "0     1788     1796     1789     1783         0         ball      4_4  22.3   \n",
      "1     1791     1789     1793     1792         1         ball      4_4  22.3   \n",
      "2     1784     1796     1802     1783         2         ball      4_4  22.3   \n",
      "3     1792     1795     1778     1789         3         ball      4_4  22.3   \n",
      "4     1801     1777     1800     1791         4         ball      4_4  22.3   \n",
      "\n",
      "      y  height    ID  experimentNo  \n",
      "0  23.7    12.5  85.0             1  \n",
      "1  23.7    12.5  85.0             1  \n",
      "2  23.7    12.5  85.0             1  \n",
      "3  23.7    12.5  85.0             1  \n",
      "4  23.7    12.5  85.0             1  \n",
      "   sensorA  sensorB  sensorC  sensorD position     x     y  height  \\\n",
      "0     1788     1796     1789     1783      4_4  22.3  23.7    12.5   \n",
      "1     1791     1789     1793     1792      4_4  22.3  23.7    12.5   \n",
      "2     1784     1796     1802     1783      4_4  22.3  23.7    12.5   \n",
      "3     1792     1795     1778     1789      4_4  22.3  23.7    12.5   \n",
      "4     1801     1777     1800     1791      4_4  22.3  23.7    12.5   \n",
      "\n",
      "   experimentNo  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "3855000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Impact-events-dataset/merged_dataset.csv', delimiter=';')\n",
    "print(df.head())\n",
    "df.drop(columns = ['sampleNo', 'typeofimpact', 'ID'], inplace = True)\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensorA  sensorB  sensorC  sensorD position     x     y  height  \\\n",
      "0     1788     1796     1789     1783      4_4  22.3  23.7    12.5   \n",
      "1     1791     1789     1793     1792      4_4  22.3  23.7    12.5   \n",
      "2     1784     1796     1802     1783      4_4  22.3  23.7    12.5   \n",
      "3     1792     1795     1778     1789      4_4  22.3  23.7    12.5   \n",
      "4     1801     1777     1800     1791      4_4  22.3  23.7    12.5   \n",
      "\n",
      "   experimentNo  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "3855000\n"
     ]
    }
   ],
   "source": [
    "positions_to_remove = ['1_1', '1_5', '5_1', '5_5']\n",
    "\n",
    "df1 = df[~df['position'].isin(positions_to_remove)]\n",
    "\n",
    "print(df1.head())\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sensorA       sensorB       sensorC       sensorD\n",
      "count  3.855000e+06  3.855000e+06  3.855000e+06  3.855000e+06\n",
      "mean   1.790466e+03  1.794333e+03  1.793815e+03  1.792419e+03\n",
      "std    8.682298e+01  1.015747e+02  8.367260e+01  1.005864e+02\n",
      "min   -3.570000e+02 -3.850000e+02 -3.520000e+02 -3.710000e+02\n",
      "25%    1.775000e+03  1.781000e+03  1.780000e+03  1.782000e+03\n",
      "50%    1.796000e+03  1.799000e+03  1.799000e+03  1.797000e+03\n",
      "75%    1.810000e+03  1.812000e+03  1.812000e+03  1.809000e+03\n",
      "max    4.048000e+03  4.057000e+03  4.040000e+03  4.055000e+03\n"
     ]
    }
   ],
   "source": [
    "sensor_columns = ['sensorA', 'sensorB', 'sensorC', 'sensorD']\n",
    "print(df[sensor_columns].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the inside points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (539, 29)\n",
      "Testing Features Shape: (232, 29)\n",
      "Training Target Shape: (539,)\n",
      "Testing Target Shape: (232,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\AppData\\Local\\Temp\\ipykernel_68384\\1807712365.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features_df = df.groupby('experimentNo').apply(extract_features).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(group):\n",
    "    features = {}\n",
    "    sensors = ['sensorA', 'sensorB', 'sensorC', 'sensorD']\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        data = group[sensor]\n",
    "        features[f'{sensor}_mean'] = data.mean()\n",
    "        features[f'{sensor}_std'] = data.std()\n",
    "        features[f'{sensor}_min'] = data.min()\n",
    "        features[f'{sensor}_max'] = data.max()\n",
    "        features[f'{sensor}_skew'] = skew(data)\n",
    "        features[f'{sensor}_kurtosis'] = kurtosis(data)\n",
    "        features[f'{sensor}_energy'] = np.sum(data**2)\n",
    "    \n",
    "    features['height'] = group['height'].iloc[0]\n",
    "    \n",
    "    features['position'] = group['position'].iloc[0]\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "features_df = df.groupby('experimentNo').apply(extract_features).reset_index(drop=True)\n",
    "\n",
    "X = features_df.drop(columns=['position'])  \n",
    "y = features_df['position']               \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Training Target Shape:\", y_train.shape)\n",
    "print(\"Testing Target Shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1 12  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0  0  0  0 10  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Iteration 2:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  2  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 10  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Iteration 3:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Iteration 4:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 11  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  9  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  2  0  0  0  0  9  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 11  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1  0  0  0  0 10  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 10]]\n",
      "Accuracy: 0.9052\n",
      "\n",
      "Iteration 5:\n",
      "Confusion Matrix:\n",
      "[[ 6  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0 15  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9569\n",
      "\n",
      "Iteration 6:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 1  0  0  0  4  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0  9  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  9]]\n",
      "Accuracy: 0.9052\n",
      "\n",
      "Iteration 7:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0  0  0  0 10  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  9]]\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Iteration 8:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 10  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9397\n",
      "\n",
      "Iteration 9:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9526\n",
      "\n",
      "Iteration 10:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  2  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Accuracies for each iteration: [0.9396551724137931, 0.9396551724137931, 0.9655172413793104, 0.9051724137931034, 0.9568965517241379, 0.9051724137931034, 0.9396551724137931, 0.9396551724137931, 0.9525862068965517, 0.9655172413793104]\n",
      "Average accuracy over 10 iterations: 0.9409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "n_estimators = 30\n",
    "max_depth = 8\n",
    "max_samples = 280  \n",
    "n_iterations = 10\n",
    "\n",
    "# To store results\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_samples=max_samples,  \n",
    "        random_state=i  \n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f\"Accuracies for each iteration: {accuracies}\")\n",
    "print(f\"Average accuracy over {n_iterations} iterations: {average_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A_B_dist': 257.0, 'A_C_dist': 361.3377921004112, 'A_D_dist': 254.0, 'B_C_dist': 254.0, 'B_D_dist': 361.3377921004112, 'C_D_dist': 257.0}\n"
     ]
    }
   ],
   "source": [
    "sensor_positions = {\n",
    "    'A': (33,30),\n",
    "    'B': (33, 287),\n",
    "    'C': (287,287),\n",
    "    'D': (287,30),\n",
    "}\n",
    "\n",
    "def calculate_distances(sensor_positions):\n",
    "    distances = {}\n",
    "    keys = list(sensor_positions.keys())\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            key1, key2 = keys[i], keys[j]\n",
    "            pos1, pos2 = sensor_positions[key1], sensor_positions[key2]\n",
    "            distance = np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "            distances[f'{key1}_{key2}_dist'] = distance\n",
    "    return distances\n",
    "\n",
    "distances = calculate_distances(sensor_positions)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\AppData\\Local\\Temp\\ipykernel_27892\\1539558969.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features_df = df.groupby('experimentNo').apply(extract_features, distances=distances).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_features(group, distances):\n",
    "    features = {}\n",
    "    sensors = ['sensorA', 'sensorB', 'sensorC', 'sensorD']\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        data = group[sensor]\n",
    "        \n",
    "        features[f'{sensor}_mean'] = data.mean()\n",
    "        features[f'{sensor}_std'] = data.std()\n",
    "        features[f'{sensor}_min'] = data.min()\n",
    "        features[f'{sensor}_max'] = data.max()\n",
    "        features[f'{sensor}_range'] = data.max() - data.min()\n",
    "        features[f'{sensor}_skew'] = skew(data)\n",
    "        features[f'{sensor}_kurtosis'] = kurtosis(data)\n",
    "        \n",
    "    \n",
    "    features['height'] = group['height'].iloc[0]\n",
    "    \n",
    "    #for key, value in distances.items():\n",
    "    #    features[key] = value\n",
    "    \n",
    "    features['position'] = group['position'].iloc[0]\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "features_df = df.groupby('experimentNo').apply(extract_features, distances=distances).reset_index(drop=True)\n",
    "\n",
    "X = features_df.drop(columns=['position'])\n",
    "y = features_df['position']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9741\n",
      "\n",
      "Iteration 2:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  3  8  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9483\n",
      "\n",
      "Iteration 3:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Iteration 4:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  2  9  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9569\n",
      "\n",
      "Iteration 5:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9698\n",
      "\n",
      "Iteration 6:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 10  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Iteration 7:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Iteration 8:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  1  9  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  9]]\n",
      "Accuracy: 0.9267\n",
      "\n",
      "Iteration 9:\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Iteration 10:\n",
      "Confusion Matrix:\n",
      "[[ 7  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11]]\n",
      "Accuracy: 0.9655\n",
      "\n",
      "Average accuracy over 10 iterations: 0.9603\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "max_depth = 10\n",
    "max_samples = 280  \n",
    "n_iterations = 10\n",
    "\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_samples=max_samples,  \n",
    "        random_state=i  \n",
    "    )\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "#print(f\"Accuracies for each iteration: {accuracies}\")\n",
    "print(f\"Average accuracy over {n_iterations} iterations: {average_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(style=\"dark\")\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='rocket', cbar=True, \n",
    "                xticklabels=labels, yticklabels=labels, linewidths=0.5, square=True)\n",
    "    \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "unique_labels = sorted(y.unique())\n",
    "plot_confusion_matrix(y_test, y_pred, labels=unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\TUD\\WHK2\\PINNs\\.conda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:09:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9267241379310345\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_2       1.00      1.00      1.00         8\n",
      "         1_3       1.00      0.92      0.96        13\n",
      "         1_4       0.93      1.00      0.96        13\n",
      "         2_1       0.90      0.90      0.90        10\n",
      "         2_2       1.00      0.83      0.91        12\n",
      "         2_3       0.86      1.00      0.92        12\n",
      "         2_4       0.83      1.00      0.91        15\n",
      "         2_5       0.89      1.00      0.94         8\n",
      "         3_1       0.60      1.00      0.75         3\n",
      "         3_2       1.00      0.86      0.92        14\n",
      "         3_3       0.89      0.94      0.92        18\n",
      "         3_4       0.88      1.00      0.93         7\n",
      "         3_5       0.87      0.81      0.84        16\n",
      "         4_1       1.00      0.92      0.96        12\n",
      "         4_2       1.00      0.77      0.87        13\n",
      "         4_3       1.00      1.00      1.00         9\n",
      "         4_4       0.89      1.00      0.94         8\n",
      "         4_5       1.00      0.82      0.90        11\n",
      "         5_2       0.86      1.00      0.92         6\n",
      "         5_3       1.00      0.92      0.96        13\n",
      "         5_4       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.93       232\n",
      "   macro avg       0.92      0.94      0.92       232\n",
      "weighted avg       0.94      0.93      0.93       232\n",
      "\n",
      "SVM Accuracy: 0.8620689655172413\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_2       1.00      0.62      0.77         8\n",
      "         1_3       0.71      0.92      0.80        13\n",
      "         1_4       1.00      0.77      0.87        13\n",
      "         2_1       0.67      1.00      0.80        10\n",
      "         2_2       0.69      0.75      0.72        12\n",
      "         2_3       0.86      1.00      0.92        12\n",
      "         2_4       1.00      0.80      0.89        15\n",
      "         2_5       0.38      0.62      0.48         8\n",
      "         3_1       1.00      1.00      1.00         3\n",
      "         3_2       0.88      1.00      0.93        14\n",
      "         3_3       1.00      0.78      0.88        18\n",
      "         3_4       0.70      1.00      0.82         7\n",
      "         3_5       1.00      0.50      0.67        16\n",
      "         4_1       1.00      1.00      1.00        12\n",
      "         4_2       1.00      0.85      0.92        13\n",
      "         4_3       1.00      1.00      1.00         9\n",
      "         4_4       0.73      1.00      0.84         8\n",
      "         4_5       1.00      1.00      1.00        11\n",
      "         5_2       1.00      1.00      1.00         6\n",
      "         5_3       1.00      1.00      1.00        13\n",
      "         5_4       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.86       232\n",
      "   macro avg       0.89      0.88      0.87       232\n",
      "weighted avg       0.90      0.86      0.86       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_predictions))\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, xgb_predictions, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\TUD\\WHK2\\PINNs\\.conda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0727 - loss: 3.0157 - val_accuracy: 0.1852 - val_loss: 2.8692\n",
      "Epoch 2/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2770 - loss: 2.7330 - val_accuracy: 0.2685 - val_loss: 2.6831\n",
      "Epoch 3/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3472 - loss: 2.4560 - val_accuracy: 0.3056 - val_loss: 2.5027\n",
      "Epoch 4/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4658 - loss: 2.1625 - val_accuracy: 0.3981 - val_loss: 2.2854\n",
      "Epoch 5/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5464 - loss: 1.8836 - val_accuracy: 0.4074 - val_loss: 2.0438\n",
      "Epoch 6/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6926 - loss: 1.5146 - val_accuracy: 0.5000 - val_loss: 1.7709\n",
      "Epoch 7/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 1.3326 - val_accuracy: 0.5370 - val_loss: 1.5140\n",
      "Epoch 8/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 1.0983 - val_accuracy: 0.5463 - val_loss: 1.3354\n",
      "Epoch 9/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7979 - loss: 0.8934 - val_accuracy: 0.6759 - val_loss: 1.1734\n",
      "Epoch 10/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.7371 - val_accuracy: 0.7037 - val_loss: 1.0793\n",
      "Epoch 11/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.6742 - val_accuracy: 0.7778 - val_loss: 0.9570\n",
      "Epoch 12/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.5740 - val_accuracy: 0.7963 - val_loss: 0.9003\n",
      "Epoch 13/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.4710 - val_accuracy: 0.8426 - val_loss: 0.7978\n",
      "Epoch 14/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.4334 - val_accuracy: 0.8056 - val_loss: 0.7901\n",
      "Epoch 15/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.3663 - val_accuracy: 0.8796 - val_loss: 0.7055\n",
      "Epoch 16/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.3397 - val_accuracy: 0.8519 - val_loss: 0.6910\n",
      "Epoch 17/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.2897 - val_accuracy: 0.8889 - val_loss: 0.6358\n",
      "Epoch 18/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.2763 - val_accuracy: 0.8889 - val_loss: 0.6232\n",
      "Epoch 19/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.2434 - val_accuracy: 0.8981 - val_loss: 0.5858\n",
      "Epoch 20/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.1906 - val_accuracy: 0.9074 - val_loss: 0.5886\n",
      "Epoch 21/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.1896 - val_accuracy: 0.9074 - val_loss: 0.5552\n",
      "Epoch 22/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.1479 - val_accuracy: 0.9074 - val_loss: 0.5454\n",
      "Epoch 23/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.1379 - val_accuracy: 0.9167 - val_loss: 0.5529\n",
      "Epoch 24/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.1430 - val_accuracy: 0.9259 - val_loss: 0.5273\n",
      "Epoch 25/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.1182 - val_accuracy: 0.9259 - val_loss: 0.5260\n",
      "Epoch 26/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.1155 - val_accuracy: 0.9259 - val_loss: 0.5210\n",
      "Epoch 27/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0940 - val_accuracy: 0.9259 - val_loss: 0.5167\n",
      "Epoch 28/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0888 - val_accuracy: 0.9259 - val_loss: 0.5071\n",
      "Epoch 29/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0902 - val_accuracy: 0.9259 - val_loss: 0.5229\n",
      "Epoch 30/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0785 - val_accuracy: 0.9352 - val_loss: 0.5015\n",
      "Epoch 31/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0726 - val_accuracy: 0.9352 - val_loss: 0.5077\n",
      "Epoch 32/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0735 - val_accuracy: 0.9352 - val_loss: 0.5110\n",
      "Epoch 33/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0676 - val_accuracy: 0.9352 - val_loss: 0.5228\n",
      "Epoch 34/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0571 - val_accuracy: 0.9352 - val_loss: 0.5142\n",
      "Epoch 35/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0582 - val_accuracy: 0.9352 - val_loss: 0.5176\n",
      "Epoch 36/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0450 - val_accuracy: 0.9352 - val_loss: 0.5220\n",
      "Epoch 37/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0515 - val_accuracy: 0.9352 - val_loss: 0.5319\n",
      "Epoch 38/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0436 - val_accuracy: 0.9352 - val_loss: 0.5189\n",
      "Epoch 39/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0512 - val_accuracy: 0.9352 - val_loss: 0.5335\n",
      "Epoch 40/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0337 - val_accuracy: 0.9352 - val_loss: 0.5371\n",
      "Epoch 41/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0411 - val_accuracy: 0.9352 - val_loss: 0.5350\n",
      "Epoch 42/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0425 - val_accuracy: 0.9352 - val_loss: 0.5412\n",
      "Epoch 43/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0495 - val_accuracy: 0.9352 - val_loss: 0.5285\n",
      "Epoch 44/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0326 - val_accuracy: 0.9352 - val_loss: 0.5428\n",
      "Epoch 45/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0329 - val_accuracy: 0.9352 - val_loss: 0.5514\n",
      "Epoch 46/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0251 - val_accuracy: 0.9352 - val_loss: 0.5621\n",
      "Epoch 47/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0247 - val_accuracy: 0.9352 - val_loss: 0.5567\n",
      "Epoch 48/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0303 - val_accuracy: 0.9352 - val_loss: 0.5456\n",
      "Epoch 49/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0357 - val_accuracy: 0.9352 - val_loss: 0.5726\n",
      "Epoch 50/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0302 - val_accuracy: 0.9352 - val_loss: 0.5519\n",
      "Epoch 51/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0210 - val_accuracy: 0.9352 - val_loss: 0.5632\n",
      "Epoch 52/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.9352 - val_loss: 0.5763\n",
      "Epoch 53/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0204 - val_accuracy: 0.9352 - val_loss: 0.5660\n",
      "Epoch 54/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0291 - val_accuracy: 0.9352 - val_loss: 0.5880\n",
      "Epoch 55/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0205 - val_accuracy: 0.9352 - val_loss: 0.5660\n",
      "Epoch 56/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0297 - val_accuracy: 0.9352 - val_loss: 0.6134\n",
      "Epoch 57/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0287 - val_accuracy: 0.9352 - val_loss: 0.5777\n",
      "Epoch 58/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0193 - val_accuracy: 0.9352 - val_loss: 0.5790\n",
      "Epoch 59/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0202 - val_accuracy: 0.9352 - val_loss: 0.5840\n",
      "Epoch 60/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0207 - val_accuracy: 0.9352 - val_loss: 0.6155\n",
      "Epoch 61/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0289 - val_accuracy: 0.9352 - val_loss: 0.5884\n",
      "Epoch 62/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0219 - val_accuracy: 0.9352 - val_loss: 0.6105\n",
      "Epoch 63/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9352 - val_loss: 0.5822\n",
      "Epoch 64/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0121 - val_accuracy: 0.9352 - val_loss: 0.5950\n",
      "Epoch 65/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9352 - val_loss: 0.6324\n",
      "Epoch 66/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9352 - val_loss: 0.6114\n",
      "Epoch 67/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0123 - val_accuracy: 0.9352 - val_loss: 0.5967\n",
      "Epoch 68/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0106 - val_accuracy: 0.9352 - val_loss: 0.6283\n",
      "Epoch 69/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9352 - val_loss: 0.6176\n",
      "Epoch 70/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0130 - val_accuracy: 0.9352 - val_loss: 0.6199\n",
      "Epoch 71/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9352 - val_loss: 0.6180\n",
      "Epoch 72/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0094 - val_accuracy: 0.9352 - val_loss: 0.6250\n",
      "Epoch 73/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9352 - val_loss: 0.6264\n",
      "Epoch 74/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9352 - val_loss: 0.6279\n",
      "Epoch 75/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9352 - val_loss: 0.6362\n",
      "Epoch 76/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9352 - val_loss: 0.6356\n",
      "Epoch 77/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9352 - val_loss: 0.6370\n",
      "Epoch 78/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9352 - val_loss: 0.6388\n",
      "Epoch 79/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9352 - val_loss: 0.6422\n",
      "Epoch 80/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9352 - val_loss: 0.6416\n",
      "Epoch 81/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9352 - val_loss: 0.6456\n",
      "Epoch 82/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0092 - val_accuracy: 0.9352 - val_loss: 0.6385\n",
      "Epoch 83/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9352 - val_loss: 0.6584\n",
      "Epoch 84/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0077 - val_accuracy: 0.9352 - val_loss: 0.6555\n",
      "Epoch 85/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9352 - val_loss: 0.6382\n",
      "Epoch 86/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9352 - val_loss: 0.6557\n",
      "Epoch 87/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9352 - val_loss: 0.6613\n",
      "Epoch 88/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9352 - val_loss: 0.6561\n",
      "Epoch 89/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9352 - val_loss: 0.6616\n",
      "Epoch 90/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9352 - val_loss: 0.6655\n",
      "Epoch 91/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9352 - val_loss: 0.6616\n",
      "Epoch 92/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9352 - val_loss: 0.6656\n",
      "Epoch 93/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9352 - val_loss: 0.6691\n",
      "Epoch 94/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9352 - val_loss: 0.6708\n",
      "Epoch 95/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9352 - val_loss: 0.6753\n",
      "Epoch 96/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9352 - val_loss: 0.6687\n",
      "Epoch 97/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9352 - val_loss: 0.6759\n",
      "Epoch 98/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9352 - val_loss: 0.6809\n",
      "Epoch 99/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9352 - val_loss: 0.6787\n",
      "Epoch 100/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9352 - val_loss: 0.6803\n",
      "Epoch 101/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9352 - val_loss: 0.6869\n",
      "Epoch 102/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9352 - val_loss: 0.6817\n",
      "Epoch 103/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9352 - val_loss: 0.6973\n",
      "Epoch 104/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9352 - val_loss: 0.6848\n",
      "Epoch 105/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9352 - val_loss: 0.6858\n",
      "Epoch 106/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9352 - val_loss: 0.6966\n",
      "Epoch 107/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9352 - val_loss: 0.6937\n",
      "Epoch 108/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9352 - val_loss: 0.6916\n",
      "Epoch 109/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9352 - val_loss: 0.6975\n",
      "Epoch 110/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9352 - val_loss: 0.7011\n",
      "Epoch 111/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9352 - val_loss: 0.7035\n",
      "Epoch 112/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9352 - val_loss: 0.7081\n",
      "Epoch 113/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9352 - val_loss: 0.7032\n",
      "Epoch 114/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9352 - val_loss: 0.7046\n",
      "Epoch 115/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9352 - val_loss: 0.7108\n",
      "Epoch 116/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9352 - val_loss: 0.7097\n",
      "Epoch 117/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9352 - val_loss: 0.7103\n",
      "Epoch 118/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9352 - val_loss: 0.7113\n",
      "Epoch 119/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9352 - val_loss: 0.7137\n",
      "Epoch 120/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9352 - val_loss: 0.7162\n",
      "Epoch 121/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9352 - val_loss: 0.7150\n",
      "Epoch 122/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9352 - val_loss: 0.7165\n",
      "Epoch 123/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9352 - val_loss: 0.7178\n",
      "Epoch 124/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9352 - val_loss: 0.7228\n",
      "Epoch 125/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9352 - val_loss: 0.7226\n",
      "Epoch 126/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9352 - val_loss: 0.7314\n",
      "Epoch 127/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9352 - val_loss: 0.7244\n",
      "Epoch 128/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9352 - val_loss: 0.7351\n",
      "Epoch 129/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9352 - val_loss: 0.7289\n",
      "Epoch 130/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9352 - val_loss: 0.7266\n",
      "Epoch 131/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9352 - val_loss: 0.7474\n",
      "Epoch 132/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9352 - val_loss: 0.7299\n",
      "Epoch 133/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0077 - val_accuracy: 0.9352 - val_loss: 0.7984\n",
      "Epoch 134/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0117 - val_accuracy: 0.9352 - val_loss: 0.7431\n",
      "Epoch 135/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0057 - val_accuracy: 0.9352 - val_loss: 0.7463\n",
      "Epoch 136/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9352 - val_loss: 0.7618\n",
      "Epoch 137/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9352 - val_loss: 0.7267\n",
      "Epoch 138/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9352 - val_loss: 0.7757\n",
      "Epoch 139/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0112 - val_accuracy: 0.9352 - val_loss: 0.7128\n",
      "Epoch 140/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9352 - val_loss: 0.7419\n",
      "Epoch 141/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9352 - val_loss: 0.7716\n",
      "Epoch 142/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9352 - val_loss: 0.7345\n",
      "Epoch 143/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9352 - val_loss: 0.7302\n",
      "Epoch 144/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9352 - val_loss: 0.7458\n",
      "Epoch 145/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9352 - val_loss: 0.7460\n",
      "Epoch 146/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9352 - val_loss: 0.7424\n",
      "Epoch 147/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9352 - val_loss: 0.7437\n",
      "Epoch 148/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9352 - val_loss: 0.7449\n",
      "Epoch 149/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9352 - val_loss: 0.7470\n",
      "Epoch 150/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9352 - val_loss: 0.7539\n",
      "Epoch 151/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9352 - val_loss: 0.7559\n",
      "Epoch 152/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9352 - val_loss: 0.7528\n",
      "Epoch 153/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9352 - val_loss: 0.7521\n",
      "Epoch 154/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9352 - val_loss: 0.7561\n",
      "Epoch 155/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9352 - val_loss: 0.7615\n",
      "Epoch 156/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9352 - val_loss: 0.7634\n",
      "Epoch 157/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9352 - val_loss: 0.7613\n",
      "Epoch 158/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9352 - val_loss: 0.7663\n",
      "Epoch 159/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9352 - val_loss: 0.7645\n",
      "Epoch 160/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9352 - val_loss: 0.7688\n",
      "Epoch 161/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.4309e-04 - val_accuracy: 0.9352 - val_loss: 0.7699\n",
      "Epoch 162/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9352 - val_loss: 0.7703\n",
      "Epoch 163/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9352 - val_loss: 0.7733\n",
      "Epoch 164/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9639e-04 - val_accuracy: 0.9352 - val_loss: 0.7759\n",
      "Epoch 165/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8585e-04 - val_accuracy: 0.9352 - val_loss: 0.7739\n",
      "Epoch 166/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9352 - val_loss: 0.7746\n",
      "Epoch 167/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1398e-04 - val_accuracy: 0.9352 - val_loss: 0.7787\n",
      "Epoch 168/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1307e-04 - val_accuracy: 0.9352 - val_loss: 0.7792\n",
      "Epoch 169/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4790e-04 - val_accuracy: 0.9352 - val_loss: 0.7804\n",
      "Epoch 170/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8884e-04 - val_accuracy: 0.9352 - val_loss: 0.7803\n",
      "Epoch 171/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9635e-04 - val_accuracy: 0.9352 - val_loss: 0.7796\n",
      "Epoch 172/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2204e-04 - val_accuracy: 0.9352 - val_loss: 0.7822\n",
      "Epoch 173/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3306e-04 - val_accuracy: 0.9352 - val_loss: 0.7833\n",
      "Epoch 174/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5404e-04 - val_accuracy: 0.9352 - val_loss: 0.7873\n",
      "Epoch 175/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4375e-04 - val_accuracy: 0.9352 - val_loss: 0.7878\n",
      "Epoch 176/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5589e-04 - val_accuracy: 0.9352 - val_loss: 0.7879\n",
      "Epoch 177/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3804e-04 - val_accuracy: 0.9352 - val_loss: 0.7926\n",
      "Epoch 178/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7810e-04 - val_accuracy: 0.9352 - val_loss: 0.7912\n",
      "Epoch 179/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4157e-04 - val_accuracy: 0.9352 - val_loss: 0.7927\n",
      "Epoch 180/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2096e-04 - val_accuracy: 0.9352 - val_loss: 0.7934\n",
      "Epoch 181/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1654e-04 - val_accuracy: 0.9352 - val_loss: 0.7973\n",
      "Epoch 182/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5449e-04 - val_accuracy: 0.9352 - val_loss: 0.7945\n",
      "Epoch 183/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4077e-04 - val_accuracy: 0.9352 - val_loss: 0.7993\n",
      "Epoch 184/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.5816e-04 - val_accuracy: 0.9352 - val_loss: 0.8002\n",
      "Epoch 185/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3570e-04 - val_accuracy: 0.9352 - val_loss: 0.8013\n",
      "Epoch 186/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2825e-04 - val_accuracy: 0.9352 - val_loss: 0.8011\n",
      "Epoch 187/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3894e-04 - val_accuracy: 0.9352 - val_loss: 0.8024\n",
      "Epoch 188/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6313e-04 - val_accuracy: 0.9352 - val_loss: 0.8056\n",
      "Epoch 189/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7745e-04 - val_accuracy: 0.9352 - val_loss: 0.8060\n",
      "Epoch 190/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1836e-04 - val_accuracy: 0.9352 - val_loss: 0.8059\n",
      "Epoch 191/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2078e-04 - val_accuracy: 0.9352 - val_loss: 0.8043\n",
      "Epoch 192/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6582e-04 - val_accuracy: 0.9352 - val_loss: 0.8088\n",
      "Epoch 193/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3146e-04 - val_accuracy: 0.9352 - val_loss: 0.8100\n",
      "Epoch 194/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1584e-04 - val_accuracy: 0.9352 - val_loss: 0.8119\n",
      "Epoch 195/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7236e-04 - val_accuracy: 0.9352 - val_loss: 0.8135\n",
      "Epoch 196/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7507e-04 - val_accuracy: 0.9352 - val_loss: 0.8131\n",
      "Epoch 197/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9340e-04 - val_accuracy: 0.9352 - val_loss: 0.8142\n",
      "Epoch 198/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2606e-04 - val_accuracy: 0.9352 - val_loss: 0.8165\n",
      "Epoch 199/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9310e-04 - val_accuracy: 0.9352 - val_loss: 0.8170\n",
      "Epoch 200/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2226e-04 - val_accuracy: 0.9352 - val_loss: 0.8184\n",
      "Epoch 201/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8223e-04 - val_accuracy: 0.9352 - val_loss: 0.8180\n",
      "Epoch 202/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8945e-04 - val_accuracy: 0.9352 - val_loss: 0.8237\n",
      "Epoch 203/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0125e-04 - val_accuracy: 0.9352 - val_loss: 0.8232\n",
      "Epoch 204/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1138e-04 - val_accuracy: 0.9352 - val_loss: 0.8212\n",
      "Epoch 205/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8601e-04 - val_accuracy: 0.9352 - val_loss: 0.8241\n",
      "Epoch 206/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1879e-04 - val_accuracy: 0.9352 - val_loss: 0.8234\n",
      "Epoch 207/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4306e-04 - val_accuracy: 0.9352 - val_loss: 0.8277\n",
      "Epoch 208/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2650e-04 - val_accuracy: 0.9352 - val_loss: 0.8292\n",
      "Epoch 209/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.5051e-04 - val_accuracy: 0.9352 - val_loss: 0.8313\n",
      "Epoch 210/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6704e-04 - val_accuracy: 0.9352 - val_loss: 0.8314\n",
      "Epoch 211/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6381e-04 - val_accuracy: 0.9352 - val_loss: 0.8322\n",
      "Epoch 212/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6432e-04 - val_accuracy: 0.9352 - val_loss: 0.8310\n",
      "Epoch 213/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7686e-04 - val_accuracy: 0.9352 - val_loss: 0.8333\n",
      "Epoch 214/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9731e-04 - val_accuracy: 0.9352 - val_loss: 0.8355\n",
      "Epoch 215/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7320e-04 - val_accuracy: 0.9352 - val_loss: 0.8362\n",
      "Epoch 216/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5056e-04 - val_accuracy: 0.9352 - val_loss: 0.8374\n",
      "Epoch 217/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8184e-04 - val_accuracy: 0.9352 - val_loss: 0.8373\n",
      "Epoch 218/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7302e-04 - val_accuracy: 0.9352 - val_loss: 0.8375\n",
      "Epoch 219/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6406e-04 - val_accuracy: 0.9352 - val_loss: 0.8400\n",
      "Epoch 220/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0986e-04 - val_accuracy: 0.9352 - val_loss: 0.8416\n",
      "Epoch 221/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2935e-04 - val_accuracy: 0.9352 - val_loss: 0.8419\n",
      "Epoch 222/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7240e-04 - val_accuracy: 0.9352 - val_loss: 0.8419\n",
      "Epoch 223/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4382e-04 - val_accuracy: 0.9352 - val_loss: 0.8441\n",
      "Epoch 224/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8953e-04 - val_accuracy: 0.9352 - val_loss: 0.8449\n",
      "Epoch 225/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9786e-04 - val_accuracy: 0.9352 - val_loss: 0.8462\n",
      "Epoch 226/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7459e-04 - val_accuracy: 0.9352 - val_loss: 0.8475\n",
      "Epoch 227/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2170e-04 - val_accuracy: 0.9352 - val_loss: 0.8498\n",
      "Epoch 228/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7277e-04 - val_accuracy: 0.9352 - val_loss: 0.8486\n",
      "Epoch 229/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7505e-04 - val_accuracy: 0.9352 - val_loss: 0.8494\n",
      "Epoch 230/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4383e-04 - val_accuracy: 0.9352 - val_loss: 0.8516\n",
      "Epoch 231/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5852e-04 - val_accuracy: 0.9352 - val_loss: 0.8545\n",
      "Epoch 232/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7696e-04 - val_accuracy: 0.9352 - val_loss: 0.8537\n",
      "Epoch 233/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9371e-04 - val_accuracy: 0.9352 - val_loss: 0.8561\n",
      "Epoch 234/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1066e-04 - val_accuracy: 0.9352 - val_loss: 0.8555\n",
      "Epoch 235/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4779e-04 - val_accuracy: 0.9352 - val_loss: 0.8563\n",
      "Epoch 236/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1493e-04 - val_accuracy: 0.9352 - val_loss: 0.8586\n",
      "Epoch 237/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6506e-04 - val_accuracy: 0.9352 - val_loss: 0.8581\n",
      "Epoch 238/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6411e-04 - val_accuracy: 0.9352 - val_loss: 0.8577\n",
      "Epoch 239/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2228e-04 - val_accuracy: 0.9352 - val_loss: 0.8644\n",
      "Epoch 240/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5159e-04 - val_accuracy: 0.9352 - val_loss: 0.8653\n",
      "Epoch 241/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4582e-04 - val_accuracy: 0.9352 - val_loss: 0.8622\n",
      "Epoch 242/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0368e-04 - val_accuracy: 0.9352 - val_loss: 0.8625\n",
      "Epoch 243/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6675e-04 - val_accuracy: 0.9352 - val_loss: 0.8638\n",
      "Epoch 244/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6782e-04 - val_accuracy: 0.9352 - val_loss: 0.8645\n",
      "Epoch 245/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4638e-04 - val_accuracy: 0.9352 - val_loss: 0.8669\n",
      "Epoch 246/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5262e-04 - val_accuracy: 0.9352 - val_loss: 0.8674\n",
      "Epoch 247/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2448e-04 - val_accuracy: 0.9352 - val_loss: 0.8677\n",
      "Epoch 248/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2157e-04 - val_accuracy: 0.9352 - val_loss: 0.8672\n",
      "Epoch 249/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9922e-04 - val_accuracy: 0.9352 - val_loss: 0.8693\n",
      "Epoch 250/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3426e-04 - val_accuracy: 0.9352 - val_loss: 0.8720\n",
      "Epoch 251/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2145e-04 - val_accuracy: 0.9352 - val_loss: 0.8728\n",
      "Epoch 252/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7278e-04 - val_accuracy: 0.9352 - val_loss: 0.8718\n",
      "Epoch 253/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8051e-04 - val_accuracy: 0.9352 - val_loss: 0.8749\n",
      "Epoch 254/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0409e-04 - val_accuracy: 0.9352 - val_loss: 0.8744\n",
      "Epoch 255/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8453e-04 - val_accuracy: 0.9352 - val_loss: 0.8746\n",
      "Epoch 256/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1645e-04 - val_accuracy: 0.9352 - val_loss: 0.8771\n",
      "Epoch 257/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8870e-04 - val_accuracy: 0.9352 - val_loss: 0.8771\n",
      "Epoch 258/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3162e-04 - val_accuracy: 0.9352 - val_loss: 0.8782\n",
      "Epoch 259/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6946e-04 - val_accuracy: 0.9352 - val_loss: 0.8820\n",
      "Epoch 260/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9292e-04 - val_accuracy: 0.9352 - val_loss: 0.8807\n",
      "Epoch 261/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8245e-04 - val_accuracy: 0.9352 - val_loss: 0.8805\n",
      "Epoch 262/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7281e-04 - val_accuracy: 0.9352 - val_loss: 0.8833\n",
      "Epoch 263/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5594e-04 - val_accuracy: 0.9352 - val_loss: 0.8820\n",
      "Epoch 264/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0437e-04 - val_accuracy: 0.9352 - val_loss: 0.8851\n",
      "Epoch 265/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8292e-04 - val_accuracy: 0.9352 - val_loss: 0.8842\n",
      "Epoch 266/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4191e-04 - val_accuracy: 0.9352 - val_loss: 0.8895\n",
      "Epoch 267/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4385e-04 - val_accuracy: 0.9352 - val_loss: 0.8877\n",
      "Epoch 268/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3275e-04 - val_accuracy: 0.9352 - val_loss: 0.8890\n",
      "Epoch 269/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4002e-04 - val_accuracy: 0.9352 - val_loss: 0.8907\n",
      "Epoch 270/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8011e-04 - val_accuracy: 0.9352 - val_loss: 0.8902\n",
      "Epoch 271/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4466e-04 - val_accuracy: 0.9352 - val_loss: 0.8905\n",
      "Epoch 272/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5099e-04 - val_accuracy: 0.9352 - val_loss: 0.8929\n",
      "Epoch 273/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0884e-04 - val_accuracy: 0.9352 - val_loss: 0.8932\n",
      "Epoch 274/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3679e-04 - val_accuracy: 0.9352 - val_loss: 0.8942\n",
      "Epoch 275/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5016e-04 - val_accuracy: 0.9352 - val_loss: 0.8942\n",
      "Epoch 276/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2985e-04 - val_accuracy: 0.9352 - val_loss: 0.8953\n",
      "Epoch 277/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2877e-04 - val_accuracy: 0.9352 - val_loss: 0.8965\n",
      "Epoch 278/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3034e-04 - val_accuracy: 0.9352 - val_loss: 0.8982\n",
      "Epoch 279/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4639e-04 - val_accuracy: 0.9352 - val_loss: 0.9008\n",
      "Epoch 280/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0865e-04 - val_accuracy: 0.9352 - val_loss: 0.9006\n",
      "Epoch 281/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2225e-04 - val_accuracy: 0.9352 - val_loss: 0.9007\n",
      "Epoch 282/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0461e-04 - val_accuracy: 0.9352 - val_loss: 0.9015\n",
      "Epoch 283/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9591e-04 - val_accuracy: 0.9352 - val_loss: 0.9035\n",
      "Epoch 284/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1529e-04 - val_accuracy: 0.9352 - val_loss: 0.9019\n",
      "Epoch 285/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4562e-04 - val_accuracy: 0.9352 - val_loss: 0.9061\n",
      "Epoch 286/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9697e-04 - val_accuracy: 0.9352 - val_loss: 0.9071\n",
      "Epoch 287/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2349e-04 - val_accuracy: 0.9352 - val_loss: 0.9051\n",
      "Epoch 288/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1007e-04 - val_accuracy: 0.9352 - val_loss: 0.9040\n",
      "Epoch 289/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8946e-04 - val_accuracy: 0.9352 - val_loss: 0.9046\n",
      "Epoch 290/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7552e-04 - val_accuracy: 0.9352 - val_loss: 0.9100\n",
      "Epoch 291/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7220e-04 - val_accuracy: 0.9352 - val_loss: 0.9100\n",
      "Epoch 292/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6595e-04 - val_accuracy: 0.9352 - val_loss: 0.9087\n",
      "Epoch 293/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8413e-04 - val_accuracy: 0.9352 - val_loss: 0.9091\n",
      "Epoch 294/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7792e-04 - val_accuracy: 0.9352 - val_loss: 0.9106\n",
      "Epoch 295/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7558e-04 - val_accuracy: 0.9352 - val_loss: 0.9124\n",
      "Epoch 296/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9187e-04 - val_accuracy: 0.9352 - val_loss: 0.9135\n",
      "Epoch 297/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0741e-04 - val_accuracy: 0.9352 - val_loss: 0.9123\n",
      "Epoch 298/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9409e-04 - val_accuracy: 0.9352 - val_loss: 0.9142\n",
      "Epoch 299/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7142e-04 - val_accuracy: 0.9352 - val_loss: 0.9169\n",
      "Epoch 300/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5445e-04 - val_accuracy: 0.9352 - val_loss: 0.9171\n",
      "Epoch 301/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2184e-04 - val_accuracy: 0.9352 - val_loss: 0.9204\n",
      "Epoch 302/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8507e-04 - val_accuracy: 0.9352 - val_loss: 0.9212\n",
      "Epoch 303/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8404e-04 - val_accuracy: 0.9352 - val_loss: 0.9203\n",
      "Epoch 304/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1190e-04 - val_accuracy: 0.9352 - val_loss: 0.9206\n",
      "Epoch 305/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7530e-04 - val_accuracy: 0.9352 - val_loss: 0.9211\n",
      "Epoch 306/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6992e-04 - val_accuracy: 0.9352 - val_loss: 0.9234\n",
      "Epoch 307/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7921e-04 - val_accuracy: 0.9352 - val_loss: 0.9228\n",
      "Epoch 308/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5073e-04 - val_accuracy: 0.9352 - val_loss: 0.9234\n",
      "Epoch 309/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7620e-04 - val_accuracy: 0.9352 - val_loss: 0.9275\n",
      "Epoch 310/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4220e-04 - val_accuracy: 0.9352 - val_loss: 0.9288\n",
      "Epoch 311/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4923e-04 - val_accuracy: 0.9352 - val_loss: 0.9283\n",
      "Epoch 312/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3830e-04 - val_accuracy: 0.9352 - val_loss: 0.9284\n",
      "Epoch 313/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5285e-04 - val_accuracy: 0.9352 - val_loss: 0.9288\n",
      "Epoch 314/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6812e-04 - val_accuracy: 0.9352 - val_loss: 0.9298\n",
      "Epoch 315/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4021e-04 - val_accuracy: 0.9352 - val_loss: 0.9298\n",
      "Epoch 316/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8656e-04 - val_accuracy: 0.9352 - val_loss: 0.9339\n",
      "Epoch 317/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3669e-04 - val_accuracy: 0.9352 - val_loss: 0.9344\n",
      "Epoch 318/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5311e-04 - val_accuracy: 0.9352 - val_loss: 0.9318\n",
      "Epoch 319/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4143e-04 - val_accuracy: 0.9352 - val_loss: 0.9319\n",
      "Epoch 320/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4260e-04 - val_accuracy: 0.9352 - val_loss: 0.9362\n",
      "Epoch 321/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2538e-04 - val_accuracy: 0.9352 - val_loss: 0.9371\n",
      "Epoch 322/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5270e-04 - val_accuracy: 0.9352 - val_loss: 0.9356\n",
      "Epoch 323/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5869e-04 - val_accuracy: 0.9352 - val_loss: 0.9365\n",
      "Epoch 324/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2698e-04 - val_accuracy: 0.9352 - val_loss: 0.9385\n",
      "Epoch 325/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3138e-04 - val_accuracy: 0.9352 - val_loss: 0.9386\n",
      "Epoch 326/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4300e-04 - val_accuracy: 0.9352 - val_loss: 0.9419\n",
      "Epoch 327/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2931e-04 - val_accuracy: 0.9352 - val_loss: 0.9410\n",
      "Epoch 328/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2333e-04 - val_accuracy: 0.9352 - val_loss: 0.9410\n",
      "Epoch 329/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2823e-04 - val_accuracy: 0.9352 - val_loss: 0.9416\n",
      "Epoch 330/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2377e-04 - val_accuracy: 0.9352 - val_loss: 0.9435\n",
      "Epoch 331/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3237e-04 - val_accuracy: 0.9352 - val_loss: 0.9424\n",
      "Epoch 332/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2418e-04 - val_accuracy: 0.9352 - val_loss: 0.9440\n",
      "Epoch 333/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1741e-04 - val_accuracy: 0.9352 - val_loss: 0.9436\n",
      "Epoch 334/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5013e-04 - val_accuracy: 0.9352 - val_loss: 0.9458\n",
      "Epoch 335/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1851e-04 - val_accuracy: 0.9352 - val_loss: 0.9463\n",
      "Epoch 336/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1991e-04 - val_accuracy: 0.9352 - val_loss: 0.9487\n",
      "Epoch 337/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2392e-04 - val_accuracy: 0.9352 - val_loss: 0.9484\n",
      "Epoch 338/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1465e-04 - val_accuracy: 0.9352 - val_loss: 0.9497\n",
      "Epoch 339/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2003e-04 - val_accuracy: 0.9352 - val_loss: 0.9504\n",
      "Epoch 340/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2301e-04 - val_accuracy: 0.9352 - val_loss: 0.9514\n",
      "Epoch 341/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2113e-04 - val_accuracy: 0.9352 - val_loss: 0.9519\n",
      "Epoch 342/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2618e-04 - val_accuracy: 0.9352 - val_loss: 0.9512\n",
      "Epoch 343/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3162e-04 - val_accuracy: 0.9352 - val_loss: 0.9539\n",
      "Epoch 344/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1095e-04 - val_accuracy: 0.9352 - val_loss: 0.9533\n",
      "Epoch 345/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1624e-04 - val_accuracy: 0.9352 - val_loss: 0.9549\n",
      "Epoch 346/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1788e-04 - val_accuracy: 0.9352 - val_loss: 0.9566\n",
      "Epoch 347/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0891e-04 - val_accuracy: 0.9352 - val_loss: 0.9565\n",
      "Epoch 348/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0124e-04 - val_accuracy: 0.9352 - val_loss: 0.9562\n",
      "Epoch 349/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0887e-04 - val_accuracy: 0.9352 - val_loss: 0.9577\n",
      "Epoch 350/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1081e-04 - val_accuracy: 0.9352 - val_loss: 0.9589\n",
      "Epoch 351/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0062e-04 - val_accuracy: 0.9352 - val_loss: 0.9608\n",
      "Epoch 352/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9546e-05 - val_accuracy: 0.9352 - val_loss: 0.9606\n",
      "Epoch 353/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0868e-04 - val_accuracy: 0.9352 - val_loss: 0.9618\n",
      "Epoch 354/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0618e-04 - val_accuracy: 0.9352 - val_loss: 0.9620\n",
      "Epoch 355/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0979e-04 - val_accuracy: 0.9352 - val_loss: 0.9603\n",
      "Epoch 356/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0645e-04 - val_accuracy: 0.9352 - val_loss: 0.9627\n",
      "Epoch 357/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1046e-05 - val_accuracy: 0.9352 - val_loss: 0.9638\n",
      "Epoch 358/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.3036e-05 - val_accuracy: 0.9352 - val_loss: 0.9646\n",
      "Epoch 359/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1159e-04 - val_accuracy: 0.9352 - val_loss: 0.9645\n",
      "Epoch 360/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0013e-04 - val_accuracy: 0.9352 - val_loss: 0.9665\n",
      "Epoch 361/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3944e-05 - val_accuracy: 0.9352 - val_loss: 0.9669\n",
      "Epoch 362/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.0351e-05 - val_accuracy: 0.9352 - val_loss: 0.9666\n",
      "Epoch 363/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9496e-05 - val_accuracy: 0.9352 - val_loss: 0.9687\n",
      "Epoch 364/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6591e-05 - val_accuracy: 0.9352 - val_loss: 0.9695\n",
      "Epoch 365/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8180e-05 - val_accuracy: 0.9352 - val_loss: 0.9682\n",
      "Epoch 366/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8083e-05 - val_accuracy: 0.9352 - val_loss: 0.9721\n",
      "Epoch 367/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5657e-05 - val_accuracy: 0.9352 - val_loss: 0.9716\n",
      "Epoch 368/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8869e-05 - val_accuracy: 0.9352 - val_loss: 0.9718\n",
      "Epoch 369/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0253e-04 - val_accuracy: 0.9352 - val_loss: 0.9721\n",
      "Epoch 370/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8874e-05 - val_accuracy: 0.9352 - val_loss: 0.9740\n",
      "Epoch 371/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2411e-05 - val_accuracy: 0.9352 - val_loss: 0.9754\n",
      "Epoch 372/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.7183e-05 - val_accuracy: 0.9352 - val_loss: 0.9755\n",
      "Epoch 373/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4137e-05 - val_accuracy: 0.9352 - val_loss: 0.9794\n",
      "Epoch 374/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4496e-05 - val_accuracy: 0.9352 - val_loss: 0.9793\n",
      "Epoch 375/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9645e-05 - val_accuracy: 0.9352 - val_loss: 0.9770\n",
      "Epoch 376/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2902e-05 - val_accuracy: 0.9352 - val_loss: 0.9776\n",
      "Epoch 377/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.0402e-05 - val_accuracy: 0.9352 - val_loss: 0.9787\n",
      "Epoch 378/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6838e-05 - val_accuracy: 0.9352 - val_loss: 0.9810\n",
      "Epoch 379/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.0518e-05 - val_accuracy: 0.9352 - val_loss: 0.9815\n",
      "Epoch 380/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2465e-05 - val_accuracy: 0.9352 - val_loss: 0.9820\n",
      "Epoch 381/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1489e-05 - val_accuracy: 0.9352 - val_loss: 0.9825\n",
      "Epoch 382/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2054e-05 - val_accuracy: 0.9352 - val_loss: 0.9837\n",
      "Epoch 383/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.4707e-05 - val_accuracy: 0.9352 - val_loss: 0.9844\n",
      "Epoch 384/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5589e-05 - val_accuracy: 0.9352 - val_loss: 0.9833\n",
      "Epoch 385/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1301e-05 - val_accuracy: 0.9352 - val_loss: 0.9872\n",
      "Epoch 386/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4704e-05 - val_accuracy: 0.9352 - val_loss: 0.9874\n",
      "Epoch 387/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2778e-05 - val_accuracy: 0.9352 - val_loss: 0.9861\n",
      "Epoch 388/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3262e-05 - val_accuracy: 0.9352 - val_loss: 0.9877\n",
      "Epoch 389/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5147e-05 - val_accuracy: 0.9352 - val_loss: 0.9881\n",
      "Epoch 390/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5468e-05 - val_accuracy: 0.9352 - val_loss: 0.9889\n",
      "Epoch 391/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7895e-05 - val_accuracy: 0.9352 - val_loss: 0.9902\n",
      "Epoch 392/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5426e-05 - val_accuracy: 0.9352 - val_loss: 0.9896\n",
      "Epoch 393/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4113e-05 - val_accuracy: 0.9352 - val_loss: 0.9922\n",
      "Epoch 394/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8279e-05 - val_accuracy: 0.9352 - val_loss: 0.9911\n",
      "Epoch 395/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5480e-05 - val_accuracy: 0.9352 - val_loss: 0.9920\n",
      "Epoch 396/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7995e-05 - val_accuracy: 0.9352 - val_loss: 0.9921\n",
      "Epoch 397/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8103e-05 - val_accuracy: 0.9352 - val_loss: 0.9942\n",
      "Epoch 398/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6452e-05 - val_accuracy: 0.9352 - val_loss: 0.9954\n",
      "Epoch 399/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1954e-05 - val_accuracy: 0.9352 - val_loss: 0.9956\n",
      "Epoch 400/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6705e-05 - val_accuracy: 0.9352 - val_loss: 0.9966\n",
      "Epoch 401/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1637e-05 - val_accuracy: 0.9352 - val_loss: 0.9979\n",
      "Epoch 402/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4146e-05 - val_accuracy: 0.9352 - val_loss: 0.9982\n",
      "Epoch 403/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4941e-05 - val_accuracy: 0.9352 - val_loss: 0.9973\n",
      "Epoch 404/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4380e-05 - val_accuracy: 0.9352 - val_loss: 1.0008\n",
      "Epoch 405/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4156e-05 - val_accuracy: 0.9352 - val_loss: 0.9992\n",
      "Epoch 406/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9580e-05 - val_accuracy: 0.9352 - val_loss: 1.0035\n",
      "Epoch 407/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7117e-05 - val_accuracy: 0.9352 - val_loss: 1.0026\n",
      "Epoch 408/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8965e-05 - val_accuracy: 0.9352 - val_loss: 1.0016\n",
      "Epoch 409/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4190e-05 - val_accuracy: 0.9352 - val_loss: 1.0030\n",
      "Epoch 410/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0920e-05 - val_accuracy: 0.9352 - val_loss: 1.0051\n",
      "Epoch 411/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4692e-05 - val_accuracy: 0.9352 - val_loss: 1.0047\n",
      "Epoch 412/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3582e-05 - val_accuracy: 0.9352 - val_loss: 1.0053\n",
      "Epoch 413/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5151e-05 - val_accuracy: 0.9352 - val_loss: 1.0066\n",
      "Epoch 414/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5726e-05 - val_accuracy: 0.9352 - val_loss: 1.0071\n",
      "Epoch 415/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0355e-05 - val_accuracy: 0.9352 - val_loss: 1.0076\n",
      "Epoch 416/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1770e-05 - val_accuracy: 0.9352 - val_loss: 1.0087\n",
      "Epoch 417/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7773e-05 - val_accuracy: 0.9352 - val_loss: 1.0122\n",
      "Epoch 418/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3752e-05 - val_accuracy: 0.9352 - val_loss: 1.0117\n",
      "Epoch 419/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3679e-05 - val_accuracy: 0.9352 - val_loss: 1.0113\n",
      "Epoch 420/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6366e-05 - val_accuracy: 0.9352 - val_loss: 1.0141\n",
      "Epoch 421/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6987e-05 - val_accuracy: 0.9352 - val_loss: 1.0131\n",
      "Epoch 422/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3403e-05 - val_accuracy: 0.9352 - val_loss: 1.0126\n",
      "Epoch 423/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8544e-05 - val_accuracy: 0.9352 - val_loss: 1.0161\n",
      "Epoch 424/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3988e-05 - val_accuracy: 0.9352 - val_loss: 1.0177\n",
      "Epoch 425/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0373e-05 - val_accuracy: 0.9352 - val_loss: 1.0150\n",
      "Epoch 426/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9804e-05 - val_accuracy: 0.9352 - val_loss: 1.0172\n",
      "Epoch 427/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3034e-05 - val_accuracy: 0.9352 - val_loss: 1.0183\n",
      "Epoch 428/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4983e-05 - val_accuracy: 0.9352 - val_loss: 1.0177\n",
      "Epoch 429/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6798e-05 - val_accuracy: 0.9352 - val_loss: 1.0188\n",
      "Epoch 430/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4497e-05 - val_accuracy: 0.9352 - val_loss: 1.0187\n",
      "Epoch 431/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7094e-05 - val_accuracy: 0.9352 - val_loss: 1.0211\n",
      "Epoch 432/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.5516e-05 - val_accuracy: 0.9352 - val_loss: 1.0210\n",
      "Epoch 433/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8326e-05 - val_accuracy: 0.9352 - val_loss: 1.0220\n",
      "Epoch 434/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2263e-05 - val_accuracy: 0.9352 - val_loss: 1.0225\n",
      "Epoch 435/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0357e-05 - val_accuracy: 0.9352 - val_loss: 1.0237\n",
      "Epoch 436/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2519e-05 - val_accuracy: 0.9352 - val_loss: 1.0258\n",
      "Epoch 437/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0699e-05 - val_accuracy: 0.9352 - val_loss: 1.0246\n",
      "Epoch 438/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2097e-05 - val_accuracy: 0.9352 - val_loss: 1.0248\n",
      "Epoch 439/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8616e-05 - val_accuracy: 0.9352 - val_loss: 1.0262\n",
      "Epoch 440/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6636e-05 - val_accuracy: 0.9352 - val_loss: 1.0277\n",
      "Epoch 441/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7105e-05 - val_accuracy: 0.9352 - val_loss: 1.0263\n",
      "Epoch 442/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2697e-05 - val_accuracy: 0.9352 - val_loss: 1.0295\n",
      "Epoch 443/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3678e-05 - val_accuracy: 0.9352 - val_loss: 1.0297\n",
      "Epoch 444/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4979e-05 - val_accuracy: 0.9352 - val_loss: 1.0298\n",
      "Epoch 445/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1101e-05 - val_accuracy: 0.9352 - val_loss: 1.0301\n",
      "Epoch 446/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6940e-05 - val_accuracy: 0.9352 - val_loss: 1.0324\n",
      "Epoch 447/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7466e-05 - val_accuracy: 0.9352 - val_loss: 1.0330\n",
      "Epoch 448/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1161e-05 - val_accuracy: 0.9352 - val_loss: 1.0323\n",
      "Epoch 449/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9940e-05 - val_accuracy: 0.9352 - val_loss: 1.0345\n",
      "Epoch 450/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4980e-05 - val_accuracy: 0.9352 - val_loss: 1.0353\n",
      "Epoch 451/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1823e-05 - val_accuracy: 0.9352 - val_loss: 1.0359\n",
      "Epoch 452/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5736e-05 - val_accuracy: 0.9352 - val_loss: 1.0368\n",
      "Epoch 453/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5628e-05 - val_accuracy: 0.9352 - val_loss: 1.0401\n",
      "Epoch 454/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5969e-05 - val_accuracy: 0.9352 - val_loss: 1.0387\n",
      "Epoch 455/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6293e-05 - val_accuracy: 0.9352 - val_loss: 1.0389\n",
      "Epoch 456/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2543e-05 - val_accuracy: 0.9352 - val_loss: 1.0379\n",
      "Epoch 457/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0542e-05 - val_accuracy: 0.9352 - val_loss: 1.0378\n",
      "Epoch 458/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8952e-05 - val_accuracy: 0.9352 - val_loss: 1.0421\n",
      "Epoch 459/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7026e-05 - val_accuracy: 0.9352 - val_loss: 1.0423\n",
      "Epoch 460/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5147e-05 - val_accuracy: 0.9352 - val_loss: 1.0404\n",
      "Epoch 461/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0821e-05 - val_accuracy: 0.9352 - val_loss: 1.0432\n",
      "Epoch 462/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8295e-05 - val_accuracy: 0.9352 - val_loss: 1.0435\n",
      "Epoch 463/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8848e-05 - val_accuracy: 0.9352 - val_loss: 1.0467\n",
      "Epoch 464/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9589e-05 - val_accuracy: 0.9352 - val_loss: 1.0465\n",
      "Epoch 465/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5877e-05 - val_accuracy: 0.9352 - val_loss: 1.0464\n",
      "Epoch 466/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9709e-05 - val_accuracy: 0.9352 - val_loss: 1.0473\n",
      "Epoch 467/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5123e-05 - val_accuracy: 0.9352 - val_loss: 1.0481\n",
      "Epoch 468/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3013e-05 - val_accuracy: 0.9352 - val_loss: 1.0479\n",
      "Epoch 469/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5053e-05 - val_accuracy: 0.9352 - val_loss: 1.0495\n",
      "Epoch 470/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5704e-05 - val_accuracy: 0.9352 - val_loss: 1.0497\n",
      "Epoch 471/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1013e-05 - val_accuracy: 0.9352 - val_loss: 1.0496\n",
      "Epoch 472/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9913e-05 - val_accuracy: 0.9352 - val_loss: 1.0507\n",
      "Epoch 473/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1746e-05 - val_accuracy: 0.9352 - val_loss: 1.0533\n",
      "Epoch 474/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9825e-05 - val_accuracy: 0.9352 - val_loss: 1.0542\n",
      "Epoch 475/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3678e-05 - val_accuracy: 0.9352 - val_loss: 1.0544\n",
      "Epoch 476/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9706e-05 - val_accuracy: 0.9352 - val_loss: 1.0546\n",
      "Epoch 477/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4871e-05 - val_accuracy: 0.9352 - val_loss: 1.0544\n",
      "Epoch 478/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0830e-05 - val_accuracy: 0.9352 - val_loss: 1.0542\n",
      "Epoch 479/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6150e-05 - val_accuracy: 0.9352 - val_loss: 1.0573\n",
      "Epoch 480/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0077e-05 - val_accuracy: 0.9352 - val_loss: 1.0558\n",
      "Epoch 481/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9577e-05 - val_accuracy: 0.9352 - val_loss: 1.0580\n",
      "Epoch 482/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8371e-05 - val_accuracy: 0.9352 - val_loss: 1.0590\n",
      "Epoch 483/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3133e-05 - val_accuracy: 0.9352 - val_loss: 1.0589\n",
      "Epoch 484/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4470e-05 - val_accuracy: 0.9352 - val_loss: 1.0607\n",
      "Epoch 485/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0495e-05 - val_accuracy: 0.9352 - val_loss: 1.0594\n",
      "Epoch 486/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0432e-05 - val_accuracy: 0.9352 - val_loss: 1.0614\n",
      "Epoch 487/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3894e-05 - val_accuracy: 0.9352 - val_loss: 1.0618\n",
      "Epoch 488/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7328e-05 - val_accuracy: 0.9352 - val_loss: 1.0624\n",
      "Epoch 489/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7896e-05 - val_accuracy: 0.9352 - val_loss: 1.0632\n",
      "Epoch 490/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7469e-05 - val_accuracy: 0.9352 - val_loss: 1.0640\n",
      "Epoch 491/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7711e-05 - val_accuracy: 0.9352 - val_loss: 1.0642\n",
      "Epoch 492/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8866e-05 - val_accuracy: 0.9352 - val_loss: 1.0638\n",
      "Epoch 493/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8093e-05 - val_accuracy: 0.9352 - val_loss: 1.0659\n",
      "Epoch 494/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1381e-05 - val_accuracy: 0.9352 - val_loss: 1.0680\n",
      "Epoch 495/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1935e-05 - val_accuracy: 0.9352 - val_loss: 1.0676\n",
      "Epoch 496/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9836e-05 - val_accuracy: 0.9352 - val_loss: 1.0676\n",
      "Epoch 497/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0765e-05 - val_accuracy: 0.9352 - val_loss: 1.0681\n",
      "Epoch 498/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8274e-05 - val_accuracy: 0.9352 - val_loss: 1.0693\n",
      "Epoch 499/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8575e-05 - val_accuracy: 0.9352 - val_loss: 1.0702\n",
      "Epoch 500/500\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6542e-05 - val_accuracy: 0.9352 - val_loss: 1.0710\n",
      "Test Accuracy: 93.97%\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FE13996DE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "           3       0.91      1.00      0.95        10\n",
      "           4       1.00      0.92      0.96        12\n",
      "           5       0.92      1.00      0.96        12\n",
      "           6       1.00      1.00      1.00        15\n",
      "           7       0.62      1.00      0.76         8\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00        14\n",
      "          10       1.00      1.00      1.00        18\n",
      "          11       0.70      1.00      0.82         7\n",
      "          12       1.00      0.50      0.67        16\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00        13\n",
      "          15       1.00      1.00      1.00         9\n",
      "          16       0.73      1.00      0.84         8\n",
      "          17       1.00      1.00      1.00        11\n",
      "          18       1.00      0.83      0.91         6\n",
      "          19       1.00      1.00      1.00        13\n",
      "          20       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.94       232\n",
      "   macro avg       0.94      0.95      0.94       232\n",
      "weighted avg       0.96      0.94      0.94       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "num_classes = len(set(y))\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  \n",
    "    Dense(64, activation='relu'),  \n",
    "    Dense(32, activation='relu'),                                        \n",
    "    Dense(num_classes, activation='softmax')                  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=500, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracies\n",
    "\n",
    "The accuracies of the trained models are as follows:\n",
    "\n",
    "- **Neural Network**: 94%, test_accuracy: 93.7%\n",
    "- **XGBoost Classifier**: 92.6%\n",
    "- **Support Vector Machine (SVM)**: 86%\n",
    "- **Random Forest**: 96.03%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
